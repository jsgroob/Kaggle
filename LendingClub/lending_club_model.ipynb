{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import normpath, join\n",
    "import csv\n",
    "import random\n",
    "from math import log, log10, floor\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_filepath: /Users/jgroob/Documents/Resume/2017/Assignments/Octane Lending/lending-club-problem-11-07-2017/LoanStats3a-split-train.csv\n",
      "test_filepath: /Users/jgroob/Documents/Resume/2017/Assignments/Octane Lending/lending-club-problem-11-07-2017/LoanStats3a-split-test.csv\n"
     ]
    }
   ],
   "source": [
    "CURRENT_DIRECTORY = os.getcwd()\n",
    "TRAIN_CSV_NAME = \"LoanStats3a-split-train.csv\"\n",
    "TEST_CSV_NAME = \"LoanStats3a-split-test.csv\"\n",
    "train_filepath = normpath(join(CURRENT_DIRECTORY, TRAIN_CSV_NAME))\n",
    "test_filepath = normpath(join(CURRENT_DIRECTORY, TEST_CSV_NAME))\n",
    "\n",
    "print( \"train_filepath: %s\" % train_filepath)\n",
    "print( \"test_filepath: %s\" % test_filepath)\n",
    "\n",
    "training = pd.read_csv(\"LoanStats3a-split-train.csv\")\n",
    "test = pd.read_csv(\"LoanStats3a-split-test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create features from raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_features(df):\n",
    "    new_df = pd.DataFrame()\n",
    "    \n",
    "    # Prediction Variable\n",
    "    def is_default(row):\n",
    "        if row in {\"Charged Off\", \"Default\"}:\n",
    "            return 1.0\n",
    "        elif row == \"Fully Paid\":\n",
    "            return 0.0\n",
    "        raise Exception(\"Invalid status: %s\" % loan_status)\n",
    "    \n",
    "    new_df['is_default'] = df['loan_status'].apply(is_default)\n",
    "    \n",
    "    ##########################################################\n",
    "    # Creating Features\n",
    "    \n",
    "    # Per Lending Club, any Debt-to-Income Ratio > 20 is 'high'\n",
    "    new_df['high_dti'] = df.apply(lambda x: 1 if float(x['dti']) > 20 else 0, axis=1)\n",
    "    new_df['dti'] = df['dti']\n",
    "    \n",
    "    # Log Annual Income\n",
    "    new_df['annual_inc_log'] = (df['annual_inc']+1).apply('log10')\n",
    "    \n",
    "    # Revolving line utilization rate, or the amount of credit \n",
    "    # the borrower is using relative to all available revolving credit.\n",
    "    new_df['revol_util'] = (df\n",
    "                            .apply(lambda x: float(str(x['revol_util']).split('%')[0])/100\n",
    "                             , axis=1)\n",
    "                            .fillna(0)\n",
    "                           )\n",
    "    # revol_bal\n",
    "    new_df['revol_bal_log'] = (df['revol_bal']+1).apply('log10')\n",
    "    \n",
    "    # Previous Delinquency\n",
    "    new_df['previous_delinq'] = (df\n",
    "                                 .apply(lambda x: 0 if pd.isnull(x['mths_since_last_delinq']) else 1, axis=1)\n",
    "                                )\n",
    "    # Homeownership - OHE\n",
    "    def homeownership_switch(row):\n",
    "        if row in {\"MORTGAGE\", \"OWN\", \"RENT\"}:\n",
    "            return row\n",
    "    home = df['home_ownership'].apply(homeownership_switch)\n",
    "    home_ohe = pd.get_dummies(home, prefix='home')\n",
    "    new_df = pd.concat([new_df,home_ohe], axis=1)\n",
    "    \n",
    "    # Purpose - OHE\n",
    "    def purpose_switch(row):\n",
    "        if row in {\"debt_consolidation\", \"credit_card\", \"other\"\n",
    "                   , \"home_improvement\", \"major_purchase\", \"car\", \"small_business\"}:\n",
    "            return row\n",
    "    purpose = df['purpose'].apply(purpose_switch)\n",
    "    purpose_ohe = pd.get_dummies(purpose, prefix='purpose')\n",
    "    new_df = pd.concat([new_df,purpose_ohe], axis=1)\n",
    "    \n",
    "    \n",
    "    # Employement History Provided?\n",
    "    new_df['emp_length'] = df['emp_length'].apply(lambda x: 0 if pd.isna(x) else 1)\n",
    "    \n",
    "    # Employement Title Provided?\n",
    "    new_df['emp_title'] = df['emp_title'].apply(lambda x: 0 if pd.isna(x) else 1)\n",
    "    \n",
    "    # Term\n",
    "    new_df['term_60m'] = df['term'].apply(lambda x: 1 if int(x.split()[0])> 36 else 0)\n",
    "    \n",
    "    return(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_interaction_terms(df):\n",
    "    new_df = pd.DataFrame()\n",
    "    \n",
    "    new_df['int_inc_dti'] = df['annual_inc_log']*df['dti']\n",
    "    new_df['int_inc_revol_util'] = df['annual_inc_log']*df['revol_util']\n",
    "    new_df['int_dti_revol_util'] = df['dti']*df['revol_util']\n",
    "    new_df['int_inc_revol_bal_log'] = df['annual_inc_log']*df['revol_bal_log']\n",
    "\n",
    "    return(new_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Test / Train Feature Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_to_features(training)\n",
    "df_test = df_to_features(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Results DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUC metric\n",
    "def calculate_auc(y, y_pred):\n",
    "    fpr, tpr, thresholds = roc_curve(y, y_pred)\n",
    "    auc_score = auc(fpr, tpr)\n",
    "    return auc_score\n",
    "\n",
    "def pred_results(name, actual, pred):\n",
    "    \n",
    "    # AUC metric\n",
    "    def calculate_auc(y, y_pred):\n",
    "        fpr, tpr, thresholds = roc_curve(y, y_pred)\n",
    "        auc_score = auc(fpr, tpr)\n",
    "        return auc_score\n",
    "    \n",
    "    auc_score = calculate_auc(actual, pred)\n",
    "    \n",
    "    combined = pd.DataFrame({'actual':actual, 'pred': pred})\n",
    "    \n",
    "    num_pred_25 = sum(i > 0.25 for i in pred) / len(pred)\n",
    "    num_pred_50 = sum(i > 0.50 for i in pred) / len(pred)\n",
    "    num_pred_75 = sum(i > 0.75 for i in pred) / len(pred)\n",
    "    \n",
    "    defaultRate_pred_25 = combined[combined['pred']> 0.25]['actual'].mean()\n",
    "    defaultRate_pred_50 = combined[combined['pred']> 0.50]['actual'].mean()\n",
    "    defaultRate_pred_75 = combined[combined['pred']> 0.75]['actual'].mean()\n",
    "    \n",
    "    new_df = pd.DataFrame([[auc_score\n",
    "                            , num_pred_25\n",
    "                            , defaultRate_pred_25\n",
    "                            , num_pred_50\n",
    "                            , defaultRate_pred_50\n",
    "                            , num_pred_75\n",
    "                            , defaultRate_pred_75\n",
    "                           ]]\n",
    "                          , index = [name]\n",
    "                          , columns=['auc'\n",
    "                                     , 'pct_preds_greater_25pct', 'defaultRate_preds_greater_25pct'\n",
    "                                     , 'pct_preds_greater_50pct', 'defaultRate_preds_greater_50pct'\n",
    "                                     , 'pct_preds_greater_75pct', 'defaultRate_preds_greater_75pct'\n",
    "                                    ])\n",
    "    \n",
    "    return(new_df.fillna(0)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Baseline\n",
    "\n",
    "Assume Training Default rate for everyone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Default Rate AUC: 0.5\n"
     ]
    }
   ],
   "source": [
    "baseline_default_rate = df_train['is_default'].mean()\n",
    "\n",
    "y_pred = [ baseline_default_rate for x in range(len(df_test['is_default'])) ]\n",
    "\n",
    "auc_score = calculate_auc(df_test['is_default'], y_pred)\n",
    "print(\"Baseline Default Rate AUC: %s\" % auc_score)\n",
    "\n",
    "results_baseline = pred_results('avg_default_baseline', df_test['is_default'], y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Guess Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random-guess AUC: 0.456442136643\n"
     ]
    }
   ],
   "source": [
    "y_pred = [ random.choice([0.0, 1.0]) for _ in range(len(df_test['is_default'])) ]\n",
    "auc_score = calculate_auc(df_test['is_default'], y_pred)\n",
    "print(\"random-guess AUC: %s\" % auc_score)\n",
    "\n",
    "results_random = pred_results('random_baseline', df_test['is_default'], y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "annual_inc-model AUC: 0.695437380867\n"
     ]
    }
   ],
   "source": [
    "# Fit a model\n",
    "prediction_col = 'is_default'\n",
    "feature_cols = [col for col in df_train if col != prediction_col]\n",
    "\n",
    "\n",
    "# Fit a model\n",
    "seed =101010\n",
    "log_classifier = LogisticRegression(random_state = seed)\n",
    "log_classifier.fit(df_train[feature_cols],df_train[prediction_col] )\n",
    "\n",
    "\n",
    "# Annual income results\n",
    "test_preds = log_classifier.predict_proba(df_test[feature_cols])\n",
    "auc_score = calculate_auc(df_test[prediction_col].values, test_preds[:,1])\n",
    "print(\"annual_inc-model AUC: %s\" % auc_score)\n",
    "\n",
    "results_logistic = pred_results('basic_logistic_regression', df_test['is_default'], test_preds[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression with Interaction Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "annual_inc-model AUC: 0.697992311884\n"
     ]
    }
   ],
   "source": [
    "train_int = log_interaction_terms(df_train)\n",
    "test_int = log_interaction_terms(df_test)\n",
    "\n",
    "# Fit a model\n",
    "seed =101010\n",
    "log_classifier = LogisticRegression(random_state = seed)\n",
    "log_classifier.fit(pd.concat([df_train[feature_cols],train_int], axis=1)\n",
    "                   ,df_train[prediction_col] )\n",
    "\n",
    "\n",
    "# Annual income results\n",
    "test_preds = log_classifier.predict_proba(pd.concat([df_test[feature_cols],test_int], axis=1))\n",
    "auc_score = calculate_auc(df_test[prediction_col].values, test_preds[:,1])\n",
    "print(\"annual_inc-model AUC: %s\" % auc_score)\n",
    "\n",
    "results_logistic_interaction = pred_results('logistic_regression_interaction', df_test['is_default'], test_preds[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Limited Variables -- with Interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "annual_inc-model AUC: 0.678010843085\n"
     ]
    }
   ],
   "source": [
    "train_int = log_interaction_terms(df_train)\n",
    "test_int = log_interaction_terms(df_test)\n",
    "\n",
    "feature_cols = ['annual_inc_log', 'dti','high_dti', 'revol_util', 'revol_bal_log', 'term_60m']\n",
    "\n",
    "# Fit a model\n",
    "seed =101010\n",
    "log_classifier = LogisticRegression(random_state = seed)\n",
    "log_classifier.fit(pd.concat([df_train[feature_cols],train_int], axis=1)\n",
    "                   ,df_train[prediction_col] )\n",
    "\n",
    "\n",
    "# Annual income results\n",
    "test_preds = log_classifier.predict_proba(pd.concat([df_test[feature_cols],test_int], axis=1))\n",
    "auc_score = calculate_auc(df_test[prediction_col].values, test_preds[:,1])\n",
    "print(\"annual_inc-model AUC: %s\" % auc_score)\n",
    "\n",
    "results_logistic_limited_interaction = pred_results('logistic_limited_interaction', df_test['is_default'], test_preds[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost AUC: 0.869721841162\n",
      "AdaBoost Predicted Default Rate: 0.0882620564149\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "prediction_col = 'is_default'\n",
    "feature_cols = [col for col in df_train if col != prediction_col]\n",
    "\n",
    "adaboost_model = AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    n_estimators=400,\n",
    "    learning_rate=1)\n",
    "\n",
    "adaboost_model.fit(df_train[feature_cols],df_train[prediction_col])\n",
    "\n",
    "ada_preds = adaboost_model.predict_proba(df_test[feature_cols])[:,1]\n",
    "\n",
    "auc_score = calculate_auc(df_test[prediction_col].values, ada_preds)\n",
    "ada_default_rate = adaboost_model.predict(df_test[feature_cols]).mean()\n",
    "print(\"AdaBoost AUC: %s\" % auc_score)\n",
    "print(\"AdaBoost Predicted Default Rate: %s\" % ada_default_rate)\n",
    "\n",
    "results_adaboost = pred_results('adaboost', df_test['is_default'], ada_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Comparison of Models\n",
    "\n",
    "Validation done on hold-out test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auc</th>\n",
       "      <th>pct_preds_greater_25pct</th>\n",
       "      <th>defaultRate_preds_greater_25pct</th>\n",
       "      <th>pct_preds_greater_50pct</th>\n",
       "      <th>defaultRate_preds_greater_50pct</th>\n",
       "      <th>pct_preds_greater_75pct</th>\n",
       "      <th>defaultRate_preds_greater_75pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>avg_default_baseline</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_baseline</th>\n",
       "      <td>0.456442</td>\n",
       "      <td>0.509099</td>\n",
       "      <td>0.092940</td>\n",
       "      <td>0.509099</td>\n",
       "      <td>0.092940</td>\n",
       "      <td>0.509099</td>\n",
       "      <td>0.09294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>basic_logistic_regression</th>\n",
       "      <td>0.695437</td>\n",
       "      <td>0.071884</td>\n",
       "      <td>0.310127</td>\n",
       "      <td>0.003185</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logistic_regression_interaction</th>\n",
       "      <td>0.697992</td>\n",
       "      <td>0.072793</td>\n",
       "      <td>0.293750</td>\n",
       "      <td>0.003640</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logistic_limited_interaction</th>\n",
       "      <td>0.678011</td>\n",
       "      <td>0.069609</td>\n",
       "      <td>0.313725</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adaboost</th>\n",
       "      <td>0.869722</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.109645</td>\n",
       "      <td>0.088262</td>\n",
       "      <td>0.871134</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      auc  pct_preds_greater_25pct  \\\n",
       "avg_default_baseline             0.500000                 0.000000   \n",
       "random_baseline                  0.456442                 0.509099   \n",
       "basic_logistic_regression        0.695437                 0.071884   \n",
       "logistic_regression_interaction  0.697992                 0.072793   \n",
       "logistic_limited_interaction     0.678011                 0.069609   \n",
       "adaboost                         0.869722                 1.000000   \n",
       "\n",
       "                                 defaultRate_preds_greater_25pct  \\\n",
       "avg_default_baseline                                    0.000000   \n",
       "random_baseline                                         0.092940   \n",
       "basic_logistic_regression                               0.310127   \n",
       "logistic_regression_interaction                         0.293750   \n",
       "logistic_limited_interaction                            0.313725   \n",
       "adaboost                                                0.109645   \n",
       "\n",
       "                                 pct_preds_greater_50pct  \\\n",
       "avg_default_baseline                            0.000000   \n",
       "random_baseline                                 0.509099   \n",
       "basic_logistic_regression                       0.003185   \n",
       "logistic_regression_interaction                 0.003640   \n",
       "logistic_limited_interaction                    0.000455   \n",
       "adaboost                                        0.088262   \n",
       "\n",
       "                                 defaultRate_preds_greater_50pct  \\\n",
       "avg_default_baseline                                    0.000000   \n",
       "random_baseline                                         0.092940   \n",
       "basic_logistic_regression                               0.428571   \n",
       "logistic_regression_interaction                         0.375000   \n",
       "logistic_limited_interaction                            0.000000   \n",
       "adaboost                                                0.871134   \n",
       "\n",
       "                                 pct_preds_greater_75pct  \\\n",
       "avg_default_baseline                            0.000000   \n",
       "random_baseline                                 0.509099   \n",
       "basic_logistic_regression                       0.000000   \n",
       "logistic_regression_interaction                 0.000000   \n",
       "logistic_limited_interaction                    0.000000   \n",
       "adaboost                                        0.000000   \n",
       "\n",
       "                                 defaultRate_preds_greater_75pct  \n",
       "avg_default_baseline                                     0.00000  \n",
       "random_baseline                                          0.09294  \n",
       "basic_logistic_regression                                0.00000  \n",
       "logistic_regression_interaction                          0.00000  \n",
       "logistic_limited_interaction                             0.00000  \n",
       "adaboost                                                 0.00000  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_results = pd.concat([results_baseline\n",
    "    , results_random\n",
    "    , results_logistic\n",
    "    , results_logistic_interaction\n",
    "    , results_logistic_limited_interaction\n",
    "    , results_adaboost], axis=0)\n",
    "\n",
    "\n",
    "model_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "The current models simply assess, given the current loan status, if someone will default.  In my mind, this is interesting but not that practical.  Specifically, if the model determines a user is going to default, there's not much to do as the loan has already been issued.  Maybe, Lending Club could do out-reach and prevent the user from defaulting, but if the user simply doesn't have the money not much can be done.\n",
    "\n",
    "A better model would be to predict if someone is going to default before issuing the loan.\n",
    "\n",
    "To improve the model, it would be interesting to look at all of loans at the same stage (i.e. 6 months after issuance).  This would help improve the predictive power of the model by normalizing the loan states.\n",
    "\n",
    "##  Model Validation\n",
    "\n",
    "Out of the box, the logistic regression models with the simple features seem to do pretty good.  They have all have AUCs in the same range (~68%), which is considerably better then the naive / random models.  Also, the predicted default probability seems to correlate with higher actual default rates. This is a good secondary metric for assessing model quality.\n",
    "\n",
    "The Adaboost model preforms really well in terms of AUC (~87%), but the predicted probabilities appear to be on a different scale than the other models.  For example, the high risk users may have a probability >50% for the adaboost but >25% for the logistic regressions.  This isn't bad, but just something to keep in mind when compairing results between the two.\n",
    "\n",
    "\n",
    "## Additiona Feature Engineering Ideas\n",
    "Here are a few ideas on additional feature engineering:\n",
    "1. Include features on the month data\n",
    "2. Up-sample the training default rate to give more signal\n",
    "3. Create different models based on different income levels / loan sizes (i.e. use a more hierarchical approach)\n",
    "4. Dive into the variable importances of the various models to better finetune the performance.\n",
    "\n",
    "## Outstanding questions\n",
    "\n",
    "With these models, I ended up not using any time variables becuase it wasn't clear to me exactly what they represent.  For example, it's clear if all of the loans are currently outstanding with the user making payments or if some of the older loans are paid off.  This distinction is important when looking at a feature like 'months since last payment'. I would need to be 100% of when the next payment is due to use this variable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
